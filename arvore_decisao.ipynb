{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arvore_decisao.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uendercarlos/arvore_decisao/blob/master/arvore_decisao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g0lyqVymY08"
      },
      "source": [
        "# ** BÁSICO DE PYTHON **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH9sYNLpmY0_"
      },
      "source": [
        "Falar sobre a linguagem..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15GsqY5aG1EU"
      },
      "source": [
        "### Variavel\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBJU4YBtC3Zw"
      },
      "source": [
        "nome = \"uender\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YiitJevNC9E3",
        "outputId": "74882bdd-3bd0-4133-a992-c54da162fdd1"
      },
      "source": [
        "nome"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'uender'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWwZULANE_cm"
      },
      "source": [
        "idade = 31"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nakrhTfFHf6N"
      },
      "source": [
        "### Função\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg-jLNnpFFyU"
      },
      "source": [
        "def soma(idade):\n",
        "  print(\"estamos dentro da função\")\n",
        "  return idade + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuxoUwgIGDVs",
        "outputId": "cdbadc38-a694-41b1-8671-172b6564b13f"
      },
      "source": [
        "soma(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "estamos dentro da função\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzuG-pVrILDj"
      },
      "source": [
        "### Lista ou array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKlXi06YGP9f"
      },
      "source": [
        "aluno1 = \"Luciana\"\n",
        "aluno2 = \"Roberto\"\n",
        "aluno3 = \"Maria\"\n",
        "\n",
        "alunos = [\"Luciana\", \"Roberto\", \"Maria\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GipPMv3JYc0"
      },
      "source": [
        "### Laço de repetição \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYiwRVUmI-Z2",
        "outputId": "83f05bc7-d3ba-4aca-852e-744efa8f5847"
      },
      "source": [
        "for aluno in alunos:\n",
        "  print(aluno)\n",
        "  print(\"....\")\n",
        "print(\"estamos fora do laço\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Luciana\n",
            "....\n",
            "Roberto\n",
            "....\n",
            "Maria\n",
            "....\n",
            "estamos fora do laço\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO-SYdcjKDG6"
      },
      "source": [
        "### Dicionário ou objeto\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp9ICwPeKVpf"
      },
      "source": [
        "dados_alunos = {\"nome\":\"Roberto\", \"disciplina\": \"matematica\", \"nota\": \"8.5\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5AoaLbw2ML9U",
        "outputId": "726c283a-7476-4105-8c9a-b042540a24fc"
      },
      "source": [
        "dados_alunos [\"nota\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'8.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Vu5StSgEmY04"
      },
      "source": [
        "# ** AVANÇADO DE PYTHON **\n",
        "\n",
        "MACHINE LEARNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQWy4WvnmY1B"
      },
      "source": [
        "## Trabalhando com Pipelines do scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3FEgtyiLXU4"
      },
      "source": [
        "Em projetos de ciência de dados visando a construção de modelos de *machine learning*, ou aprendizado estatístico, é muito incomum que os dados iniciais estejam já no formato ideal para a construção de modelos. São necessários vários passos intermediários de pré-processamento de dados, como por exemplo a codificação de variáveis categóricas, normalização de variáveis numéricas, tratamento de dados faltantes, etc. A biblioteca **scikit-learn** -- uma das mais populares bibliotecas de código-aberto para *machine learning* no mundo -- possui diversas funções já integradas para a realização das transformações de dados mais utilizadas. Entretanto, em um fluxo comum de um modelo de aprendizado de máquina, é necessária a aplicação dessas transformações pelo menos duas vezes: a primeira vez para \"treinar\" o modelo, e depois novamente quando novos dados forem enviados como entrada para serem classificados por este modelo. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WadYn2bbmY1C"
      },
      "source": [
        "# Primeiro, realizamos a instalação do scikit-learn \n",
        "#XGBoost implementa algoritmos de aprendizado de máquina sob a estrutura Gradient Boosting\n",
        "!pip install scikit-learn==0.20.3 --upgrade\n",
        "!pip install xgboost==0.71 --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kalwelwmXzu7"
      },
      "source": [
        "## Import Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL2__uTtmY1I"
      },
      "source": [
        "#@title\n",
        "# Em seguida iremos importar diversas bibliotecas que serão utilizadas:\n",
        "\n",
        "# Pacote para trabalhar com JSON\n",
        "import json\n",
        "\n",
        "# Pacote para realizar requisições HTTP\n",
        "import requests\n",
        "\n",
        "# Pacote para exploração e análise de dados\n",
        "import pandas as pd\n",
        "\n",
        "# Pacote com métodos numéricos e representações matriciais\n",
        "import numpy as np\n",
        "\n",
        "# Pacote para construção de modelo baseado na técnica Gradient Boosting\n",
        "import xgboost as xgb\n",
        "\n",
        "# Pacotes do scikit-learn para pré-processamento de dados\n",
        "# \"SimpleImputer\" é uma transformação para preencher valores faltantes em conjuntos de dados\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Pacotes do scikit-learn para treinamento de modelos e construção de pipelines\n",
        "# Método para separação de conjunto de dados em amostras de treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Método para criação de modelos baseados em árvores de decisão\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Classe para a criação de uma pipeline de machine-learning\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Pacotes do scikit-learn para avaliação de modelos\n",
        "# Métodos para validação cruzada do modelo criado\n",
        "from sklearn.model_selection import KFold, cross_validate"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d9zujC8RA_n"
      },
      "source": [
        "# FAZER DOWNLOAD DO DATASET NO GITHUB\n",
        "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/uendercarlos/dataset_aprovado/master/dataset_alunos.csv\n",
        "df_data_1 = pd.read_csv(r'dataset_alunos.csv')\n",
        "df_data_1.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEOu6PMymY1Q"
      },
      "source": [
        "#LENDO ARQUIVO DATASET\n",
        "df_data_1 = pd.read_csv(\"dataset_alunos8.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2zV3gIcmY1Y"
      },
      "source": [
        "## Explorando os dados fornecidos\n",
        "\n",
        "\n",
        "\n",
        "Podemos continuar a exploração dos dados fornecidos com a função ``info()``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol2L23-GmY1Z"
      },
      "source": [
        "df_data_1.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyzEyR_KmY1g",
        "outputId": "29260dfa-92e4-45a3-c901-e8b4318ba721"
      },
      "source": [
        "df_data_1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6536, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtoX9qrBs0nc"
      },
      "source": [
        "#Imprima um resumo conciso de um DataSET\n",
        "df_data_1.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7yvX8Xa706t"
      },
      "source": [
        "#Conte observações distintas sobre o eixo solicitado.\n",
        "df_data_1.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3SmkRlu95sJ"
      },
      "source": [
        "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
        "print(\"Valores nulos no df_data_1 antes da transformação DropNA: \\n\\n{}\\n\".format(df_data_1.isnull().sum(axis = 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOWg8AzYwWey"
      },
      "source": [
        "## Transformação: \n",
        "\n",
        "Para o pré-processamento dos dados serão apresentadas duas transformações básicas neste notebook, demonstrando a construção de uma Pipeline com um modelo funcional. Esta Pipeline funcional fornecida deverá ser melhorada pelo participante para que o modelo final alcance a maior acurácia possíveL. Essa melhoria pode ser feita apenas no pré-processamento dos dados.\n",
        "\n",
        "A primeira transformação (passo na nossa Pipeline) será a exclusão da coluna \"NOME\" do nosso dataset, que além de não ser uma variável numérica, também não é uma variável relacionada ao desempenho dos estudantes nas disciplinas. Existem funções prontas no scikit-learn para a realização dessa transformação, entretanto nosso exemplo irá demonstrar como criar uma transformação personalizada do zero no scikit-learn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCby_sRlwWey"
      },
      "source": [
        "### Removendo todas as linhas que possuem algum valor nulos em determinadas colunas \n",
        "Usando o método Pandas **DataFrame.dropna()** você pode remover todas as linhas nulas do dataset.\n",
        "\n",
        "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wDHJXWu_O7n"
      },
      "source": [
        "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
        "print(\"Valores nulos no df_data_1 antes da transformação DropNA: \\n\\n{}\\n\".format(df_data_1.isnull().sum(axis = 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSloPp4I95sQ"
      },
      "source": [
        "# Aplicando a função para deletar todas as linhas com valor NaN na coluna ``AUSENCIA'', ``MATEMATICA'', ``PORTUGUES'', ``BIOLOGIA'':\n",
        "df_data_1 = df_data_1.dropna(axis='index', how='any', subset=['AUSENCIA', 'MATEMATICA', 'PORTUGUES', 'BIOLOGIA'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RVUR6hd995sW"
      },
      "source": [
        "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
        "print(\"Valores nulos no df_data_1 após a transformação DropNA: \\n\\n{}\\n\".format(df_data_1.isnull().sum(axis = 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptnJuUHwxsMJ"
      },
      "source": [
        "df_data_1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpJNhstrBXqv"
      },
      "source": [
        "### Converter tipos de dados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_eFqq9xVUlG"
      },
      "source": [
        " df_data_1.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86e9Dxzhf6Iy"
      },
      "source": [
        "df_data_1[\"AUSENCIA\"] = df_data_1[\"AUSENCIA\"].astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU1W7Nl4VQ6a"
      },
      "source": [
        " #Isso retorna uma série com o tipo de dados de cada coluna. \n",
        " df_data_1.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADHBcdhy-04V"
      },
      "source": [
        "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
        "print(\"Valores nulos no df_training_dataset antes da transformação DropNA: \\n\\n{}\\n\".format(df_data_1.isnull().sum(axis = 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJM_SoohmY2E"
      },
      "source": [
        "### Excluindo colunas do dataset\n",
        "\n",
        "Para a criação de uma transformação de dados personalizada no scikit-learn, é necessária basicamente a criação de uma classe com os métodos ``transform`` e ``fit``. No método transform será executada a lógica da nossa transformação.\n",
        "\n",
        "Na próxima célula é apresentado o código completo de uma transformação ``DropColumns`` para a remoção de colunas de um DataFrame pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byd3ubL_mY2F"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "# All sklearn Transforms must have the `transform` and `fit` methods\n",
        "class DropColumns(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        # Primeiro realizamos a cópia do dataframe 'X' de entrada\n",
        "        data = X.copy()\n",
        "        # Retornamos um novo dataframe sem as colunas indesejadas\n",
        "        return data.drop(labels=self.columns, axis='columns')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOFFdGZumY2L"
      },
      "source": [
        "Para aplicar essa transformação em um DataFrame pandas, basta instanciar um objeto *DropColumns* e chamar o método transform()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16BykmGemY2L",
        "outputId": "227f5c7a-c8cf-4950-ad5c-e63c833bc345"
      },
      "source": [
        "# Instanciando uma transformação DropColumns\n",
        "rm_columns = DropColumns(\n",
        "    columns=[\"NOME\"]  # Essa transformação recebe como parâmetro uma lista com os nomes das colunas indesejadas\n",
        ")\n",
        "\n",
        "print(rm_columns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DropColumns(columns=['NOME'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PxsmiMXmY2T"
      },
      "source": [
        "# Visualizando as colunas do dataset original\n",
        "print(\"Colunas do dataset original: \\n\")\n",
        "print(df_data_1.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKCZafOvmY2X"
      },
      "source": [
        "# Aplicando a transformação ``DropColumns`` ao conjunto de dados base\n",
        "rm_columns.fit(X=df_data_1)\n",
        "\n",
        "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
        "df_data_2 = pd.DataFrame.from_records(\n",
        "    data=rm_columns.transform(\n",
        "        X=df_data_1\n",
        "    ),\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psTECYY7mY2c"
      },
      "source": [
        "# Visualizando as colunas do dataset transformado\n",
        "print(\"Colunas do dataset após a transformação ``DropColumns``: \\n\")\n",
        "print(df_data_2.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMG2E00IQhND"
      },
      "source": [
        "# df_DATA_1 AINDA POSSUI NOME\n",
        "df_data_2.head(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvQuNq3lmY2h"
      },
      "source": [
        "Nota-se que a coluna \"NOME\" foi removida e nosso dataset agora poossui apenas 5 colunas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTTzUP3KwVwL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9PEk9D1v47W"
      },
      "source": [
        "### Renomear coluna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMpsFCAAvbIA"
      },
      "source": [
        "# renomear coluna\n",
        "df_data_2 = df_data_2.rename(columns={'AUSENCIA': 'FALTAS'})\n",
        "#ou\n",
        "#df.rename(columns={'nome': 'nome_completo'}, inplace = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUwvO-LJLdQz"
      },
      "source": [
        "## Visualizações\n",
        "\n",
        "Para visualizar o dataset fornecido, podemos utilizar as bibliotecas ``matplotlib`` e ``seaborn``:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRVzV-JJLi0S"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFsfFA-2Li9_"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
        "\n",
        "sns.countplot(ax=axes[0], x='AUSENCIA', data=df_data_1)\n",
        "sns.countplot(ax=axes[1], x='MATEMATICA', data=df_data_1)\n",
        "sns.countplot(ax=axes[2], x='PORTUGUES', data=df_data_1)\n",
        "sns.countplot(ax=axes[3], x='BIOLOGIA', data=df_data_1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az3njh-6LjHU"
      },
      "source": [
        "#Gere o gráfico de estimativa de densidade do kernel\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
        "\n",
        "sns.distplot(df_data_1['AUSENCIA'].dropna(), ax=axes[0])\n",
        "sns.distplot(df_data_1['MATEMATICA'], ax=axes[1])\n",
        "sns.distplot(df_data_1['PORTUGUES'], ax=axes[2])\n",
        "sns.distplot(df_data_1['BIOLOGIA'], ax=axes[3])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BqqD84yLjav"
      },
      "source": [
        "fig = plt.plot()\n",
        "sns.countplot(x='RESULTADO', data=df_data_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEiq4DdYmY23"
      },
      "source": [
        "## Treinando um modelo de classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP5-6BRJmY2-"
      },
      "source": [
        "### Definindo as features do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG8fVdQxh9fg"
      },
      "source": [
        "# Definição das colunas que serão features (nota-se que a coluna NOME não está presente)\n",
        "features = [\n",
        "    \"FALTAS\", \"MATEMATICA\", 'PORTUGUES', 'BIOLOGIA', \n",
        "]\n",
        "\n",
        "# Definição da variável-alvo\n",
        "target = [\"RESULTADO\"]\n",
        "\n",
        "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
        "X = df_data_2[features]\n",
        "y = df_data_2[target]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0YosyFhmY3I"
      },
      "source": [
        "O conjunto de entrada (X):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbVlNVHPmY3J"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS_txtY-mY3O"
      },
      "source": [
        "As variáveis-alvo correspondentes (y):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4p-1WeEmY3P"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbg9zC4mmY3X"
      },
      "source": [
        "### Separando o dataset em um conjunto de treino e um conjunto de teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7pDea5omY3Y"
      },
      "source": [
        "Iremos separar o dataset fornecido em dois grupos: um para treinar nosso modelo, e outro para testarmos o resultado através de um teste cego. A separação do dataset pode ser feita facilmente com o método *train_test_split()* do scikit-learn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "virc4JjymY3Y"
      },
      "source": [
        "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2D0EwccmY3d"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fdh8j2_mY3e"
      },
      "source": [
        "### Criando um modelo baseado em árvores de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhlIH7cWmY3f"
      },
      "source": [
        "No exemplo fornecido iremos criar um classificador baseado em **árvores de decisão**.\n",
        "\n",
        "Material teórico sobre árvores de decisão na documentação oficial do scikit-learn: https://scikit-learn.org/stable/modules/tree.html\n",
        "\n",
        "O primeiro passo é basicamente instanciar um objeto *DecisionTreeClassifier()* da biblioteca scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLdqolrXmY3i"
      },
      "source": [
        "# Criação de uma árvore de decisão com a biblioteca ``scikit-learn``:\n",
        "decision_tree = DecisionTreeClassifier()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BTjY6oDmY3m"
      },
      "source": [
        "### Testando o classificador baseado em árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG0-6xNWmY3n"
      },
      "source": [
        "# Treino do modelo (é chamado o método *fit()* com os conjuntos de treino)\n",
        "decision_tree.fit(\n",
        "    X_train,\n",
        "    y_train\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddxsP3_kmY3s"
      },
      "source": [
        "### Execução de predições e avaliação da árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcDnczDAmY3t"
      },
      "source": [
        "# Realização de teste cego no modelo criado\n",
        "y_pred = decision_tree.predict(X_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbn-k0XCmY3y"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YScRfOQ3mY33",
        "outputId": "a8859c94-3e2e-4c29-d566-359ced297497"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['REPROVADO' 'APROVADO' 'APROVADO' ... 'APROVADO' 'APROVADO' 'APROVADO']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KXleV40mY38"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Acurácia alcançada pela árvore de decisão\n",
        "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuqtW-U17Pgq"
      },
      "source": [
        "### Testar modelo em uma matriz de confusao"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjB0a9xKaKVO"
      },
      "source": [
        "# matriz de confusão é para avaliar a qualidade da saída do nosso classificador\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdx8NPvuaNNJ"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['APROVADO', 'REPROVADO'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZSWBj_Fx19V"
      },
      "source": [
        "### Salvando a folha de respostas como um arquivo .csv para ser submetido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "FnUmrudhALnM",
        "outputId": "8d768d3e-89ef-4700-b07d-479b20a00158"
      },
      "source": [
        "from google.colab import files\n",
        "df_data_2.to_csv('dataset_alunos.csv') \n",
        "files.download('dataset_alunos.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f2182400-6a36-4901-9b8e-9f059ef7e3f6\", \"meu_dataset.csv\", 176256)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ygOATtMmY4H"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-LkA10_mY4I"
      },
      "source": [
        "Neste notebook foi demonstrado como trabalhar com transformações e modelos com a biblioteca scikit-learn. É recomendado que o participante realize seus experimentos editando o código fornecido aqui até que um modelo com acurácia elevada seja alcançado.\n",
        "\n",
        "Quando você estiver satisfeito com seu modelo, pode passar para a segunda etapa do desafio -- encapsular seu modelo como uma API REST pronta para uso em uma ferramenta Machine Learning!\n",
        "\n"
      ]
    }
  ]
}